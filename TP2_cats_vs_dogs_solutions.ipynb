{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP2_cats_vs_dogs_solutions.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsabalcagarayestia/jeuJsSabalcagaray/blob/master/TP2_cats_vs_dogs_solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtYBTjgTpro0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3NqBPitp2pX",
        "colab_type": "text"
      },
      "source": [
        "# TP2 : Cats vs Dogs\n",
        "\n",
        "Dans la vraie vie : \n",
        "- les images sont plus complèxes que MNIST : variation d'échelle, de background, d'angle de vue, etc... \n",
        "- Un grand nombre d'images sont nécessaire, elles peuvent ne pas rentrer dans la RAM...\n",
        "- UN GPU est nécessaire pour accélérer le temps de calcul.\n",
        "\n",
        "\n",
        "This tutorial follows a basic machine learning workflow:\n",
        "\n",
        "\n",
        "1. Examine and understand data\n",
        "2. Build an input pipeline\n",
        "3. Build the model\n",
        "4. Train the model\n",
        "5. Test the model\n",
        "6. Improve the model and repeat the process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngZsNI9b3Rjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "import os # use to read files and directories.\n",
        "import numpy as np # array format, marix operations\n",
        "import matplotlib.pyplot as plt # library for plots\n",
        "\n",
        "# various classes that we will use :\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV36EF9TNLx2",
        "colab_type": "text"
      },
      "source": [
        "travailler avec un GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axgOlBFM20-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pItLF6ZA3vEf",
        "colab_type": "text"
      },
      "source": [
        "## 1. Les données\n",
        "### 1.1 charger les données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWyhI1di343g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em54JtS54FqL",
        "colab_type": "text"
      },
      "source": [
        "The dataset has the following directory structure:\n",
        "\n",
        "<pre>\n",
        "<b>cats_and_dogs_filtered</b>\n",
        "|__ <b>train</b>\n",
        "    |______ <b>cats</b>: [cat.0.jpg, cat.1.jpg, cat.2.jpg ....]\n",
        "    |______ <b>dogs</b>: [dog.0.jpg, dog.1.jpg, dog.2.jpg ...]\n",
        "|__ <b>validation</b>\n",
        "    |______ <b>cats</b>: [cat.2000.jpg, cat.2001.jpg, cat.2002.jpg ....]\n",
        "    |______ <b>dogs</b>: [dog.2000.jpg, dog.2001.jpg, dog.2002.jpg ...]\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChL2v2Oh4HcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz7CkMoD4Y8J",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 Comprendre les données:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3Z2qi_Y4lCk",
        "colab_type": "text"
      },
      "source": [
        "**Exercice 1** : Analyser les données sur le disque. Combien il y t'il d'images de chien et de chats dans chaque dossier en training et en validation ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wHwkLzC4bzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### EXERCICE 1 \n",
        "\n",
        "## HINT : utiliser os.listdir\n",
        "num_cats_tr = \n",
        "num_dogs_tr = \n",
        "\n",
        "num_cats_val = \n",
        "num_dogs_val =\n",
        "\n",
        "total_train = \n",
        "total_val = l\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOFxPm064hFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('total training cat images:', num_cats_tr)\n",
        "print('total training dog images:', num_dogs_tr)\n",
        "\n",
        "print('total validation cat images:', num_cats_val)\n",
        "print('total validation dog images:', num_dogs_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zgFDAgl5YVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2ql6slt5bZ_",
        "colab_type": "text"
      },
      "source": [
        "## 1.3 : Préparer les données\n",
        "\n",
        "#### Ouvrir d'abord une image manuellement ?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5wkh5ts6jIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## afficher une image aléatoire de chat du training set\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "#numero de l'image à afficher\n",
        "img_index =\n",
        "\n",
        "#path de l'image\n",
        "img_name =                 ]\n",
        "img_path = \n",
        "\n",
        "#ouverture de l'image\n",
        "Image.open(img_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlUOp0OD8dHW",
        "colab_type": "text"
      },
      "source": [
        "Quelles sont vos observations sur ces images ? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUxUGS3B8nK7",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Format the images into appropriately pre-processed floating point tensors before feeding to the network:\n",
        "\n",
        "1. Read images from the disk.\n",
        "2. Decode contents of these images and convert it into proper grid format as per their RGB content.\n",
        "3. Convert them into floating point tensors.\n",
        "4. Rescale the tensors from values between 0 and 255 to values between 0 and 1, as neural networks prefer to deal with small input values.\n",
        "\n",
        "Fortunately, all these tasks can be done with the `ImageDataGenerator` class provided by `tf.keras`. It can read images from disk and preprocess them into proper tensors. It will also set up generators that convert these images into batches of tensors—helpful when training the network.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re8NjFOd5f5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our training data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuXnXpK76F6n",
        "colab_type": "text"
      },
      "source": [
        "After defining the generators for training and validation images, the `flow_from_directory method` load images from the disk, applies rescaling, and resizes the images into the required dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL6LGcss6EZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmZi2EEu6BK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfNxh-xy8xWQ",
        "colab_type": "text"
      },
      "source": [
        "visualization des images de training : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzI88vHH8z9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_training_images, _ = next(train_data_gen)\n",
        "\n",
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA4JMckV83Pi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotImages(sample_training_images[:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-ZI0y4I_bKH",
        "colab_type": "text"
      },
      "source": [
        "## 2 Le modèle "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoEYWAyf_aQ7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHvhug329BDf",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## 2.1 Création du modèle : \n",
        "\n",
        "The model consists of three convolution blocks with a max pool layer in each of them. There's a fully connected layer with 512 units on top of it that is activated by a relu activation function.\n",
        "\n",
        "** EXERCICE 2 ** : déveloper le modèle\n",
        "- 3 blocs de convolution avec du Max pooling après chacun\n",
        "- le premier bloc à une entrée "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaxNfcpD9YQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## EXERCICE\n",
        "#HINT : utiliser les classes Conv2D, MaxPooling2D, Flatten, Dense\n",
        "#padding same\n",
        "#kernel size 3\n",
        "#relu activations except for last layer\n",
        "\n",
        "model = Sequential([\n",
        "    #conv, 16 filters, input size ???\n",
        "    #max pooling\n",
        "    #conv, 32 filters\n",
        "    #max pooling\n",
        "    #conv 64\n",
        "    #max pooling\n",
        "    ## flatten\n",
        "    #DEense 512\n",
        "    # Dense ??\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnzGazgZ9Kk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4g5e9pe-0Rk",
        "colab_type": "text"
      },
      "source": [
        "compile the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eHER1HE-3py",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "no3uIjLQ-8u7",
        "colab_type": "text"
      },
      "source": [
        "model summar\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJnIYTyb-7cO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bc_tLtQS_EEV",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 entrainer le modèle :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3qfk6qN_fiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator( ## fit the model from a generator pipeline\n",
        "    train_data_gen, # the generator\n",
        "    steps_per_epoch=total_train // batch_size, # number of time to call the generator in an epoch\n",
        "    epochs=epochs, # nb of epochs\n",
        "    validation_data=val_data_gen, # a genrator for validaiton data\n",
        "    validation_steps=total_val // batch_size # number of time to call the validation generatir\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck03YJdS_mFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Op9DuvfA_sC_",
        "colab_type": "text"
      },
      "source": [
        "As you can see from the plots, training accuracy and validation accuracy are off by large margin and the model has achieved only around 70% accuracy on the validation set.\n",
        "\n",
        "Let's look at what went wrong and try to increase overall performance of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GBx7Az5HJoy",
        "colab_type": "text"
      },
      "source": [
        "In the plots above, the training accuracy is increasing linearly over time, whereas validation accuracy stalls around 70% in the training process. Also, the difference in accuracy between training and validation accuracy is noticeable—a sign of overfitting.\n",
        "\n",
        "When there are a small number of training examples, the model sometimes learns from noises or unwanted details from training examples—to an extent that it negatively impacts the performance of the model on new examples. This phenomenon is known as overfitting. It means that the model will have a difficult time generalizing on a new dataset.\n",
        "\n",
        "There are multiple ways to fight overfitting in the training process. In this tutorial, you'll use data augmentation and add dropout to our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkewXkN9o_gJ",
        "colab_type": "text"
      },
      "source": [
        "Calculer le nombre de faux positifs et faux négatifs pour chaque classe :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtECut8-o-Nc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8SKgshzHMF8",
        "colab_type": "text"
      },
      "source": [
        "## 3. Data Augmentation\n",
        "\n",
        "Overfitting generally occurs when there are a small number of training examples. One way to fix this problem is to augment the dataset so that it has a sufficient number of training examples. Data augmentation takes the approach of generating more training data from existing training samples by augmenting the samples using random transformations that yield believable-looking images. The goal is the model will never see the exact same picture twice during training. This helps expose the model to more aspects of the data and generalize better.\n",
        "\n",
        "Implement this in `tf.keras` using the `ImageDataGenerator` class. Pass  different transformations to the dataset and it will take care of applying it during the training process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kFKqOuOHPXZ",
        "colab_type": "text"
      },
      "source": [
        "### Image Flip\n",
        "\n",
        "**Exercice** : Créer un génrateur de donnée qui flip horizontallement les images de manière aléatoire. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZszbTTAHiUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Exercice :\n",
        "image_gen = ### YOUR CODE HERE #### \n",
        "train_data_gen = ###  YOUR COD EHERE ###\n",
        ": \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuuDVtVuHtbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "\n",
        "train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "\n",
        "# Re-use the same custom plotting function defined and used\n",
        "# above to visualize the training images\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmdlyIiAIuGf",
        "colab_type": "text"
      },
      "source": [
        "### Rotation aléatoire : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg-J01cRIxtn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### EXERCICE :\n",
        "\n",
        "image_gen = ## YOUR CODE HERE ##\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYChNeVHI3oq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTQeHF0TJRuQ",
        "colab_type": "text"
      },
      "source": [
        "### Zoom augmentation : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVx_3FFqJUvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## EXERCICE##\n",
        "image_gen = ####### YOUR CODE########\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uekg35V_JXn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx8nbAWAJtBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zKZ4_6sJ02P",
        "colab_type": "text"
      },
      "source": [
        "### Entrainement avec le data generator :\n",
        "\n",
        "Finalement, entrainons à nouveau le modèle avec une data génération qui intègre toute ces transformations.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqJWWoKKJ4q7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "image_gen_train = ## your code\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUUs-_JvJ7av",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='binary')\n",
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6JCKbvrKNJ4",
        "colab_type": "text"
      },
      "source": [
        "for the validation data generator : \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en9vkBR2KL3p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen_val = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
        "                                                 directory=validation_dir,\n",
        "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                 class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcwaoP7aKSVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator( ## fit the model from a generator pipeline\n",
        "    train_data_gen, # the generator\n",
        "    steps_per_epoch=total_train // batch_size, # number of time to call the generator in an epoch\n",
        "    epochs=epochs, # nb of epochs\n",
        "    validation_data=val_data_gen, # a genrator for validaiton data\n",
        "    validation_steps=total_val // batch_size # number of time to call the validation generatir\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB5t3-fnKleq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud1ranlUNss2",
        "colab_type": "text"
      },
      "source": [
        "## Dropout regularization\n",
        "\n",
        "Ajouter du dropout dans le modèle : \n",
        "\n",
        "another technique to reduce overfitting is to introduce dropout to the network. It is a form of regularization that forces the weights in the network to take only small values, which makes the distribution of weight values more regular and the network can reduce overfitting on small training examples. Dropout is one of the regularization technique used in this tutorial\n",
        "\n",
        "When you apply dropout to a layer it randomly drops out (set to zero) number of output units from the applied layer during the training process. Dropout takes a fractional number as its input value, in the form such as 0.1, 0.2, 0.4, etc. This means dropping out 10%, 20% or 40% of the output units randomly from the applied layer.\n",
        "\n",
        "When appling 0.1 dropout to a certain layer, it randomly kills 10% of the output units in each training epoch.\n",
        "\n",
        "Create a network architecture with this new dropout feature and apply it to different convolutions and fully-connected layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GfiwYuBOBG2",
        "colab_type": "text"
      },
      "source": [
        "** EXERCICE 2 **\n",
        "\n",
        "Ajouter un layer de dropout  à 20% après chaque Maxpool layer dans le modèle. Ce nouveau composant va permettre de réduire l'overfitting dans le modèle.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6bD_VHBNrzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "### EEERCICE\n",
        "model_new = ## YOUR CODE##\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nck3YlfBO4s2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_new.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "model_new.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it0IVjvHO6Hp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model_new.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val // batch_size\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_Zlr04HO_VY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa3iF5asPT4l",
        "colab_type": "text"
      },
      "source": [
        "## Utiliser un modèle pré entrainé\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTx8I-QXPYEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SHAPE = (IMG_HEIGHT, IMG_WIDTH , 3)\n",
        "\n",
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EWE83uVPdFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.trainable = False\n",
        "# Let's take a look at the base model architecture\n",
        "base_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0Q7Zar_Phfa",
        "colab_type": "text"
      },
      "source": [
        "add a classification head . \n",
        "\n",
        "To generate predictions from the block of features, average over the spatial 5x5 spatial locations, using a tf.keras.layers.GlobalAveragePooling2D layer to convert the features to a single 1280-element vector per image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12Cp9iolQhVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "prediction_layer = tf.keras.layers.Dense(1)\n",
        "\n",
        "\n",
        "model_transfer = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  global_average_layer,\n",
        "  prediction_layer\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smr-XR7hQ0c-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_transfer.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_97dtdwQ0zh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model_transfer.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val // batch_size\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4FvqI6uSpwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MleOOXSSRQpH",
        "colab_type": "text"
      },
      "source": [
        "## Fine tunning\n",
        "\n",
        "Réentrainer les autres poids du modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af873wszRu5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model.trainable = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGapccl0RzB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 100\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxqrjBI4SMSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbiFYIJVR560",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### EXERCICE : \n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam( learning_rate=0.0001)\n",
        "\n",
        "model_transfer.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSWTTdBMSBxt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fine_tune_epochs = 10\n",
        "\n",
        "history_fine_tune = model_transfer.fit_generator(\n",
        "        train_data_gen,\n",
        "        steps_per_epoch=total_train // batch_size,\n",
        "        epochs=fine_tune_epochs,\n",
        "        validation_data=val_data_gen,\n",
        "        validation_steps=total_val // batch_size\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}